{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4c0ba043-c5b2-4139-8d07-f9051378aaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d466286b9fa6498d88d6379f1e28987d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 119/119 [00:00<00:00, 438B/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ceeb8e96e748bebc44f85975f88f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"MBTI Classification.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/18j7FyHgOVOlgiO7ryvw29EHsxOSBV6js\n",
    "\"\"\"\n",
    "\n",
    "from datasets import load_dataset , Dataset\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding\n",
    "raw_datasets = load_dataset(\"Legend0300/MBTI\")\n",
    "\n",
    "\n",
    "test_dataset = load_dataset(\"Legend0300/MBTItest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32fd90d1-b6bb-4e77-91e7-98683b5e4fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'Type', 'Sentence', 'labels'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets\n",
    "\n",
    "raw_datasets[\"train\"][0][\"Type\"]\n",
    "\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8300438e-43bc-440b-bf80-afd5da760079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_labels(dataset, label_column):\n",
    "    \"\"\"\n",
    "    Find unique labels in a dataset.\n",
    "\n",
    "    Args:\n",
    "    - dataset: The dataset containing the labels.\n",
    "    - label_column: The column index or name containing the labels.\n",
    "\n",
    "    Returns:\n",
    "    - unique_labels: A list of unique labels.\n",
    "    \"\"\"\n",
    "    if isinstance(label_column, str):\n",
    "        labels = dataset[label_column]\n",
    "    else:\n",
    "        labels = [row[label_column] for row in dataset]\n",
    "    unique_labels = list(set(labels))\n",
    "    return unique_labels\n",
    "\n",
    "def create_label_mappings(unique_labels):\n",
    "    \"\"\"\n",
    "    Create label-to-id and id-to-label mappings.\n",
    "\n",
    "    Args:\n",
    "    - unique_labels: A list of unique labels.\n",
    "\n",
    "    Returns:\n",
    "    - label2id: A dictionary mapping labels to IDs.\n",
    "    - id2label: A dictionary mapping IDs to labels.\n",
    "    \"\"\"\n",
    "    label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    id2label = {idx: label for label, idx in label2id.items()}\n",
    "    return label2id, id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29dab702-6484-4150-8a10-80152d4c04f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INTP',\n",
       " 'INTJ',\n",
       " 'INFP',\n",
       " 'ISFP',\n",
       " 'ENFJ',\n",
       " 'ESFJ',\n",
       " 'INFJ',\n",
       " 'ISTP',\n",
       " 'ISTJ',\n",
       " 'ENFP',\n",
       " 'ESFP',\n",
       " 'ENTP',\n",
       " 'ESTJ',\n",
       " 'ESTP',\n",
       " 'ENTJ',\n",
       " 'ISFJ']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Assuming you have a dataset named 'data' and the label column is named 'labels'\n",
    "# Replace 'data' and 'labels' with your actual dataset and label column name.\n",
    "\n",
    "unique_labels = find_unique_labels(raw_datasets[\"train\"], 'Type')\n",
    "label2id, id2label = create_label_mappings(unique_labels)\n",
    "\n",
    "# Now you can use label2id and id2label dictionaries to map labels to IDs and vice versa.\n",
    "\n",
    "unique_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f592d06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INTP': 0,\n",
       " 'INTJ': 1,\n",
       " 'INFP': 2,\n",
       " 'ISFP': 3,\n",
       " 'ENFJ': 4,\n",
       " 'ESFJ': 5,\n",
       " 'INFJ': 6,\n",
       " 'ISTP': 7,\n",
       " 'ISTJ': 8,\n",
       " 'ENFP': 9,\n",
       " 'ESFP': 10,\n",
       " 'ENTP': 11,\n",
       " 'ESTJ': 12,\n",
       " 'ESTP': 13,\n",
       " 'ENTJ': 14,\n",
       " 'ISFJ': 15}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "321791a2-1a33-471a-8525-052139b7a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d633afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(raw_datasets[\"train\"][0][\"Sentence\"])\n",
    "inputs.tokens()\n",
    "\n",
    "inputs.word_ids()\n",
    "\n",
    "def tokenize(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"Sentence\"]\n",
    "    )\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f882d77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a08ffc7ce640219bf37defadd2563e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'Type', 'Sentence', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"].column_names\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "tokenized_datasets_test = test_dataset.map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "tokenized_datasets\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['Unnamed: 0', 'Type', 'Sentence'])\n",
    "\n",
    "tokenized_datasets_test[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2064c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87b22e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch.nn as nn\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=16,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21e2ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"MBTI-Classifier\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01\n",
    "    # push_to_hub=True,\n",
    "    # push_to_hub_model_id=\"MBTI-Classifier\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets['train'],  # Assuming you have split your dataset\n",
    "    eval_dataset=tokenized_datasets['train'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8cdb1d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15dc30a45df947d8b36a016b11a106e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted MBTI Type: ENFP\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions\n",
    "predictions = trainer.predict(tokenized_datasets_test[\"train\"])\n",
    "\n",
    "# `predictions` will contain the predicted label indices\n",
    "# You can decode these indices to get the actual labels\n",
    "predicted_label_id = np.argmax(predictions.predictions, axis=1)\n",
    "predicted_label = id2label[predicted_label_id[0]]\n",
    "\n",
    "print(\"Predicted MBTI Type:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "185b83ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 461\n",
       "})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d0240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
